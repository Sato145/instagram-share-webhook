"""
Instagramæƒ…å ±æŠ½å‡ºã‚µãƒ¼ãƒ“ã‚¹
"""

import re
import requests
from bs4 import BeautifulSoup
from . import SocialMediaInfo
from .common import clean_url


def extract_instagram_info(url, provided_username='', provided_caption=''):
    """Instagram URLã‹ã‚‰æŠ•ç¨¿æƒ…å ±ã‚’å–å¾—"""
    
    info = SocialMediaInfo()
    info.platform = 'instagram'
    
    try:
        # URLã‚’æ­£è¦åŒ–
        info.url = clean_url(url)
        
        print(f"Processing Instagram URL: {info.url}")
        
        # æŠ•ç¨¿ã‚¿ã‚¤ãƒ—åˆ¤å®š
        is_reel = '/reel/' in info.url
        is_story = '/stories/' in info.url
        
        info.is_video = is_reel
        info.type = 'ãƒªãƒ¼ãƒ«' if is_reel else 'ã‚¹ãƒˆãƒ¼ãƒªãƒ¼' if is_story else 'æŠ•ç¨¿'
        info.emoji = 'ğŸ¬' if is_reel else 'ğŸ“·'
        
        # æŠ•ç¨¿ã‚³ãƒ¼ãƒ‰æŠ½å‡º
        code_match = re.search(r'/(p|reel)/([A-Za-z0-9_-]+)', info.url)
        info.post_code = code_match.group(2) if code_match else ''
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’æŠ½å‡ºï¼ˆURLã‹ã‚‰ï¼‰
        username = None
        url_match = re.search(r'instagram\.com/([^/]+)/(p|reel)/', info.url)
        if url_match:
            potential_username = url_match.group(1)
            if potential_username not in ['www', 'p', 'reel', 'stories', 'tv']:
                username = potential_username
                print(f"âœ“ Extracted username from URL: {username}")
        
        # æä¾›ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’å„ªå…ˆ
        if provided_username:
            info.username = provided_username
            print(f"âœ“ Using provided username: {provided_username}")
        elif username:
            info.username = username
        else:
            info.username = 'Instagram'
            print(f"âš  Using fallback username: Instagram")
        
        # æä¾›ã•ã‚ŒãŸæŠ•ç¨¿æœ¬æ–‡ã‚’å„ªå…ˆ
        if provided_caption:
            info.description = provided_caption
            print(f"âœ“ Using provided caption: {provided_caption[:100]}")
        else:
            # OGã‚¿ã‚°ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
            description = _fetch_og_description(info.url)
            if description:
                info.description = description
            else:
                info.description = f'{info.username}ã•ã‚“ã®{info.type}ã‚’ãƒã‚§ãƒƒã‚¯ï¼'
        
        # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’ç”Ÿæˆ
        if info.username == 'Instagram':
            info.hashtag = '#Instagram'
        else:
            clean_username = info.username.replace(' ', '').replace('@', '')
            info.hashtag = f'#{clean_username}'
        
        print(f"âœ“ Final username: {info.username}")
        print(f"âœ“ Final description: {info.description[:100]}")
        
        return info
        
    except Exception as e:
        print(f"Error extracting Instagram info: {e}")
        import traceback
        traceback.print_exc()
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        info.url = clean_url(url)
        info.username = provided_username or 'Instagram'
        info.description = provided_caption or 'InstagramæŠ•ç¨¿ã‚’ãƒã‚§ãƒƒã‚¯ï¼'
        info.type = 'ãƒªãƒ¼ãƒ«' if '/reel/' in url else 'æŠ•ç¨¿'
        info.emoji = 'ğŸ¬' if '/reel/' in url else 'ğŸ“·'
        info.hashtag = '#Instagram'
        
        return info


def _fetch_og_description(url):
    """OGã‚¿ã‚°ã‹ã‚‰èª¬æ˜æ–‡ã‚’å–å¾—ï¼ˆãƒ™ã‚¹ãƒˆã‚¨ãƒ•ã‚©ãƒ¼ãƒˆï¼‰"""
    try:
        # æ–¹æ³•1: oEmbed API
        oembed_url = f"https://graph.facebook.com/v12.0/instagram_oembed?url={url}&access_token=&omitscript=true"
        oembed_response = requests.get(oembed_url, timeout=10)
        
        if oembed_response.status_code == 200:
            oembed_data = oembed_response.json()
            if 'title' in oembed_data and ' on Instagram:' in oembed_data['title']:
                description = oembed_data['title'].split(' on Instagram:', 1)[1].strip().strip('"').strip('"')
                if description:
                    print(f"âœ“ Extracted description from oEmbed: {description[:100]}")
                    return description
    except Exception as e:
        print(f"oEmbed API failed: {e}")
    
    # æ–¹æ³•2: HTMLãƒšãƒ¼ã‚¸ã‹ã‚‰å–å¾—
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8',
        }
        
        response = requests.get(url, headers=headers, timeout=15, allow_redirects=True)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # OGã‚¿ã‚°ã‹ã‚‰å–å¾—
            og_description = soup.find('meta', property='og:description')
            if og_description and 'content' in og_description.attrs:
                desc_text = og_description['content']
                
                # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                if ' - ' in desc_text and ' on Instagram:' in desc_text:
                    parts = desc_text.split(' on Instagram:', 1)
                    if len(parts) == 2:
                        description = parts[1].strip().strip('"').strip('"')
                        if description:
                            print(f"âœ“ Extracted description from OG tag: {description[:100]}")
                            return description
    except Exception as e:
        print(f"HTML fetch failed: {e}")
    
    return ''
