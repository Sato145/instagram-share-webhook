"""
TikTokæƒ…å ±æŠ½å‡ºã‚µãƒ¼ãƒ“ã‚¹
"""

import re
import requests
from bs4 import BeautifulSoup
from . import SocialMediaInfo
from .common import clean_url


def extract_tiktok_info(url, provided_username='', provided_caption=''):
    """TikTok URLã‹ã‚‰æŠ•ç¨¿æƒ…å ±ã‚’å–å¾—"""
    
    info = SocialMediaInfo()
    info.platform = 'tiktok'
    info.type = 'å‹•ç”»'
    info.is_video = True
    info.emoji = 'ğŸµ'
    
    try:
        # çŸ­ç¸®URLã®å ´åˆã¯å±•é–‹
        if 'vt.tiktok.com' in url or 'vm.tiktok.com' in url:
            print(f"Expanding short URL: {url}")
            expanded_url = _expand_short_url(url)
            if expanded_url:
                url = expanded_url
                print(f"âœ“ Expanded to: {url}")
        
        # URLã‚’æ­£è¦åŒ–
        info.url = clean_url(url)
        
        print(f"Processing TikTok URL: {info.url}")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’æŠ½å‡ºï¼ˆURLã‹ã‚‰ï¼‰
        # ãƒ‘ã‚¿ãƒ¼ãƒ³: https://www.tiktok.com/@username/video/1234567890
        username = None
        url_match = re.search(r'tiktok\.com/@([^/]+)', info.url)
        if url_match:
            username = url_match.group(1)
            print(f"âœ“ Extracted username from URL: {username}")
        
        # å‹•ç”»IDã‚’æŠ½å‡º
        video_match = re.search(r'/video/(\d+)', info.url)
        if video_match:
            info.post_code = video_match.group(1)
            print(f"âœ“ Extracted video ID: {info.post_code}")
        
        # æä¾›ã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’å„ªå…ˆ
        if provided_username:
            info.username = provided_username.lstrip('@')
            print(f"âœ“ Using provided username: {info.username}")
        elif username:
            info.username = username
        else:
            info.username = 'TikTok'
            print(f"âš  Using fallback username: TikTok")
        
        # æä¾›ã•ã‚ŒãŸæŠ•ç¨¿æœ¬æ–‡ã‚’å„ªå…ˆ
        if provided_caption:
            info.description = provided_caption
            print(f"âœ“ Using provided caption: {provided_caption[:100]}")
        else:
            # OGã‚¿ã‚°ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
            description = _fetch_og_description(info.url)
            if description:
                info.description = description
            else:
                info.description = f'{info.username}ã•ã‚“ã®TikTokå‹•ç”»ã‚’ãƒã‚§ãƒƒã‚¯ï¼'
        
        # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’ç”Ÿæˆ
        if info.username == 'TikTok':
            info.hashtag = '#TikTok'
        else:
            clean_username = info.username.replace(' ', '').replace('@', '')
            info.hashtag = f'#{clean_username}'
        
        print(f"âœ“ Final username: {info.username}")
        print(f"âœ“ Final description: {info.description[:100]}")
        
        return info
        
    except Exception as e:
        print(f"Error extracting TikTok info: {e}")
        import traceback
        traceback.print_exc()
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        info.url = clean_url(url)
        info.username = provided_username.lstrip('@') if provided_username else 'TikTok'
        info.description = provided_caption or 'TikTokå‹•ç”»ã‚’ãƒã‚§ãƒƒã‚¯ï¼'
        info.hashtag = '#TikTok'
        
        return info


def _expand_short_url(short_url):
    """TikTokçŸ­ç¸®URLã‚’å±•é–‹"""
    try:
        response = requests.head(short_url, allow_redirects=True, timeout=10)
        return response.url
    except Exception as e:
        print(f"Failed to expand short URL: {e}")
        return None


def _fetch_og_description(url):
    """OGã‚¿ã‚°ã‹ã‚‰èª¬æ˜æ–‡ã‚’å–å¾—ï¼ˆãƒ™ã‚¹ãƒˆã‚¨ãƒ•ã‚©ãƒ¼ãƒˆï¼‰"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8',
        }
        
        response = requests.get(url, headers=headers, timeout=15, allow_redirects=True)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # OGã‚¿ã‚°ã‹ã‚‰å–å¾—
            og_description = soup.find('meta', property='og:description')
            if og_description and 'content' in og_description.attrs:
                desc_text = og_description['content']
                
                # TikTokã®èª¬æ˜æ–‡ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                # ä¸è¦ãªæ–‡å­—åˆ—ã‚’å‰Šé™¤
                unwanted_phrases = [
                    'Watch more videos',
                    'Download the app',
                    'TikTok video from',
                ]
                for phrase in unwanted_phrases:
                    if phrase in desc_text:
                        desc_text = desc_text.split(phrase)[0].strip()
                
                if desc_text:
                    print(f"âœ“ Extracted description from OG tag: {desc_text[:100]}")
                    return desc_text
    except Exception as e:
        print(f"HTML fetch failed: {e}")
    
    return ''
